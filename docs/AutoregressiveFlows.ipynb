{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bc2e33-2282-459e-a3ba-7664d3f5dcc0",
   "metadata": {},
   "source": [
    "## An introduction of Autoregressive flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c8af7-da93-43b5-b433-03fa99be93f7",
   "metadata": {},
   "source": [
    "Recently, I am trying to apply normalizing flows to the time-series problems, and I found that Autoregressive flows are more suitable for time-series modelling than coupling flows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4a848-0d1e-448f-8609-ca0e0a43bb92",
   "metadata": {},
   "source": [
    "The joint distribution $p(\\boldsymbol{x})$ of a known time series can be expressed as follows:\n",
    "\n",
    "$$p(\\boldsymbol{x}_{1:T})=p(\\boldsymbol{x}_{1})p(\\boldsymbol{x}_{2}|\\boldsymbol{x}_{1})p(\\boldsymbol{x}_{3}|\\boldsymbol{x}_{2},\\boldsymbol{x}_{1})p(\\boldsymbol{x}_{4}|\\boldsymbol{x}_{3},\\boldsymbol{x}_{2},\\boldsymbol{x}_{1})\\ldots=\\prod_{t=1}^{T}p(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{1:t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366ee36-e1d5-4a40-9a56-7c66dc883d59",
   "metadata": {},
   "source": [
    "This is an **auto-regressive model**, and each node depends on its predecessors in the ordering. Specifically, $\\boldsymbol{x}_{t}$ is only dependent on the previous time $\\boldsymbol{x}_{1:t-1}$. \n",
    "\n",
    "It is suitable to use **autoregressive flows** to transform this joint distribution. And the dependency of special $x_i$ can be expressed as:\n",
    "\n",
    "$$x_{t}=h(u_{t};\\Theta(\\boldsymbol{x}_{1:t-1})),\\quad t=1,\\ldots,T.$$\n",
    "\n",
    "where $\\boldsymbol{u}$ contains $T$ scalar elements, that is, $\\boldsymbol{u}=(u_{1},\\ldots,u_{T})\\in\\mathbb{R}^{T}$. \n",
    "\n",
    "Specifically, we assume $h$ is affine transformation, and $\\Theta$ is a designed neural network. Its input is $\\boldsymbol{x}_{1:t-1}$, and it outputs two scalar values $\\alpha_i$ and $\\mu_i$, and they are used as scale and offset parameters in the affine transformation:\n",
    "\n",
    "$$x_{i}=u_{i}\\exp(\\alpha_{i})+\\mu_{i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087c42e-1786-44b1-9d2c-3aa5da11282c",
   "metadata": {},
   "source": [
    " **Affine autoregressive flows** is illustrated in the following figure:\n",
    "\n",
    "<center> <img src=\"imgs/af01.jpg\" width=\"700px\" /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e8505-dd8b-4156-89f4-15032846dc7e",
   "metadata": {},
   "source": [
    "The order of dependency is important for autoregressive flows. Here is an example:\n",
    "\n",
    "<center> <img src=\"imgs/af02.jpg\" width=\"700px\" /> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa89b4d-de7c-499e-930b-4fe115bceb1a",
   "metadata": {},
   "source": [
    "In the figure, (a) is the target density, where $x_1$ is depends on $x_2$.  In (b), we model the dependency with inverse order, resulting in poor results.  However, in (c), we can use a deep model to avoid this poor fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e7ceb-6d00-45a9-955f-f1190e7fe07b",
   "metadata": {},
   "source": [
    "We have already discussed that $\\Theta$ is a designed neural network, and its input is $\\boldsymbol{x}_{1:t-1}$. Naively, we need to train a neural network for each $\\boldsymbol{x}_{1:t-1}$ for $t\\in T$. Germain et al. proposed using a designed mask to improve efficiency. In his method, it will use only one neural network, illustrated as:\n",
    "\n",
    "<center> <img src=\"imgs/af03.jpg\" width=\"500px\" /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea389d6-662d-4bba-bdcc-bc4bcbf50c7b",
   "metadata": {},
   "source": [
    "The right part of the figure is the modified neural network. The number in the circle node is the dependency order (this is hyperparameters, and can be assign to different order in each layer of flows), which represent the dependency: $(x_2, x_3, x_1)$, that is, $x_1$  depends on $x_2, x_3$,  and $x_3$  depends on $x_2$. The relationship is also reflected in the inner connections between neurons in the neural network.\n",
    "\n",
    "Here, we use the idea  of the mask to modify the connection within the neural network but change the output of conditional probability to affine parameters: $\\boldsymbol{\\alpha}$ and $\\boldsymbol{\\mu}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82a246-f5b7-4811-86e1-f1521b6dffa7",
   "metadata": {},
   "source": [
    "The following code is a straightforward implementation of Autoregressive flows. I will adapt this code and use it in our project:\n",
    "\n",
    "https://github.com/ikostrikov/pytorch-flows/blob/master/flows.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512d790-3706-4c1e-9206-6ea80b262d99",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6078fe-ddb1-47c0-b584-813c128bfbb9",
   "metadata": {},
   "source": [
    "<div STYLE=\"text-indent: -36px; padding-left: 36px;\">\n",
    "    \n",
    "<p>Germain, M., Gregor, K., Murray, I. & Larochelle, H. (2015). MADE: Masked Autoencoder for Distribution Estimation. <em>Proceedings of the 32nd International Conference on Machine Learning</em>, pages 881–889.</p>\n",
    "\n",
    "<p>Jang, E. (2018) Normalizing Flows Tutorial. Retrieved from https://blog.evjang.com/2018/01/nf2.html</p>\n",
    "    \n",
    "<p>Murphy, K.P. (in press). <em>Probabilistic Machine Learning: Advanced Topics</em>. MIT Press.</p>\n",
    "    \n",
    "<p>Papamakarios, G., Pavlakou, T. & Murray, I. (2017). “ Masked Autoregressive Flow for Density Estimation”. In: <em>NIPS</em>. </p>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
