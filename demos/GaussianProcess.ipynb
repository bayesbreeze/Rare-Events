{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d642a382-db4b-4d10-8b0c-f10fc27e862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nde import distributions, flows, transforms\n",
    "import nn as nn_\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from nde.flows import realnvp\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from nde.flows import autoregressive as ar\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec346016-4b1d-407e-882f-fd133d31cc5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nde.distributions' has no attribute 'TweakedUniform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-4\u001b[39m\n\u001b[1;32m      9\u001b[0m n_total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e3\u001b[39m\n\u001b[0;32m---> 12\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTweakedUniform\u001b[49m(\n\u001b[1;32m     13\u001b[0m     low\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mzeros(dim),\n\u001b[1;32m     14\u001b[0m     high\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(dim)\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distributions\u001b[38;5;241m.\u001b[39mStandardNormal((\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_alternating_binary_mask\u001b[39m(features, even\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nde.distributions' has no attribute 'TweakedUniform'"
     ]
    }
   ],
   "source": [
    "num_flow_steps=2\n",
    "dim=2\n",
    "hidden_features=128\n",
    "num_transform_blocks=2\n",
    "dropout_probability=0.0\n",
    "use_batch_norm=0\n",
    "num_bins=128\n",
    "learning_rate = 5e-4\n",
    "n_total_steps = 1e3\n",
    "\n",
    "\n",
    "distribution = distributions.TweakedUniform(\n",
    "    low=torch.zeros(dim),\n",
    "    high=torch.ones(dim)\n",
    ")\n",
    "\n",
    "distribution = distributions.StandardNormal((2,))\n",
    "\n",
    "def create_alternating_binary_mask(features, even=True):\n",
    "    \"\"\"\n",
    "    Creates a binary mask of a given dimension which alternates its masking.\n",
    "\n",
    "    :param features: Dimension of mask.\n",
    "    :param even: If True, even values are assigned 1s, odd 0s. If False, vice versa.\n",
    "    :return: Alternating binary mask of type torch.Tensor.\n",
    "    \"\"\"\n",
    "    mask = torch.zeros(features).byte()\n",
    "    start = 0 if even else 1\n",
    "    mask[start::2] += 1\n",
    "    return mask\n",
    "\n",
    "base_transform_type = 'rq'\n",
    "def create_base_transform(i, _tail_bound):\n",
    "    if base_transform_type == 'rq':\n",
    "        return transforms.PiecewiseRationalQuadraticCouplingTransform(\n",
    "            mask=create_alternating_binary_mask(\n",
    "                features=dim,\n",
    "                even=(i % 2 == 0)\n",
    "            ),\n",
    "            transform_net_create_fn=lambda in_features, out_features:\n",
    "            nn_.ResidualNet(\n",
    "                in_features=in_features,\n",
    "                out_features=out_features,\n",
    "                hidden_features=hidden_features,\n",
    "                num_blocks=num_transform_blocks,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm\n",
    "            ),\n",
    "            num_bins=num_bins,\n",
    "            apply_unconditional_transform=False,\n",
    "            tails='linear',\n",
    "            tail_bound=_tail_bound,\n",
    "        )\n",
    "    elif base_transform_type == 'affine':\n",
    "        return transforms.AffineCouplingTransform(\n",
    "            mask=create_alternating_binary_mask(\n",
    "                features=dim,\n",
    "                even=(i % 2 == 0)\n",
    "            ),\n",
    "            transform_net_create_fn=lambda in_features, out_features:\n",
    "            nn_.ResidualNet(\n",
    "                in_features=in_features,\n",
    "                out_features=out_features,\n",
    "                hidden_features=hidden_features,\n",
    "                num_blocks=num_transform_blocks,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
